{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dcff70-8d02-491a-a945-53ee1ce19cb6",
   "metadata": {},
   "source": [
    "# LaQuacco 🍅🍅🍅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7b728-a8ea-41e4-9a10-a9ccbab594b1",
   "metadata": {},
   "source": [
    "## Laboratory Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efd4c2-cf69-4647-b7b4-f49fc268ee8c",
   "metadata": {},
   "source": [
    "### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0010f-3de0-4fd0-ae62-ae96fa0b3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import laquacco as laq  # custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116fe99-f03c-4105-b901-c53ec1bbeb4c",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e961dd-73e6-4d28-8b16-fc10d8b2b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search pattern for positive controls (if available)\n",
    "control_dir = r\".\\tests\\Richer 2023\"\n",
    "control_ext = \"*#90*tonsil*.tif\"\n",
    "control_exc = \"\"\n",
    "control_sub = False\n",
    "\n",
    "# define search pattern for QC samples\n",
    "sample_dir = r\".\\tests\\Richer 2023\"\n",
    "sample_ext = \"*#03*.tif\"\n",
    "sample_exc = \"\"\n",
    "sample_sub = False\n",
    "\n",
    "# render channel images of outliers\n",
    "show_img = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c9df8-5bf3-4a65-a34e-db1539ebd490",
   "metadata": {},
   "source": [
    "### Graphics Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dde60a-aa2c-4ddd-88d1-d1695650f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure dimensions\n",
    "dpi = plt.rcParams[\"figure.dpi\"]\n",
    "min_pixw, min_pixh = 1600, 1200\n",
    "min_width, min_height = min_pixw / dpi, min_pixh / dpi\n",
    "plt.rcParams[\"figure.figsize\"] = [min_width, min_height]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14a1c1-5db0-4b20-aab4-ba5ac7b89dcf",
   "metadata": {},
   "source": [
    "### Check samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfad8c-2286-4b4d-89e1-4afc3f6c9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list positive controls\n",
    "controls = sorted(\n",
    "    laq.get_files(\n",
    "        path=control_dir,\n",
    "        pat=control_ext,\n",
    "        anti=control_exc,\n",
    "        recurse=control_sub,\n",
    "    ),\n",
    "    key=str.lower,\n",
    ")\n",
    "controls_len = len(controls)\n",
    "print(f\"Found {controls_len} controls in {os.path.abspath(control_dir)}:\")\n",
    "for control in controls:\n",
    "    print(f\"{control.replace(control_dir, \".\")}\")\n",
    "print()\n",
    "\n",
    "# list samples\n",
    "samples = sorted(\n",
    "    laq.get_files(\n",
    "        path=sample_dir,\n",
    "        pat=sample_ext,\n",
    "        anti=sample_exc,\n",
    "        recurse=sample_sub,\n",
    "    ),\n",
    "    key=str.lower,\n",
    ")\n",
    "samples_len = len(samples)\n",
    "print(f\"Found {samples_len} samples in {os.path.abspath(sample_dir)}:\")\n",
    "for sample in samples:\n",
    "    print(f\"{sample.replace(sample_dir, \".\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6230e-2a76-4829-948a-cabf01f2966c",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f92a28-0ca2-4f6b-814b-b16bd83754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get control statistics\n",
    "controls_img_data = {}\n",
    "start = time.time()\n",
    "for count, control in enumerate(controls, start=1):\n",
    "    print(f\"CONTROL: [{count}/{controls_len}] {os.path.basename(control)}\", end=\"\", flush=True)\n",
    "    controls_img_data[control] = laq.stats_img_data(laq.get_tiff(control))  # signal above zero\n",
    "    print(f\" (-{laq.get_time_left(start, count, controls_len):.1f} s)\", flush=True)\n",
    "print()\n",
    "\n",
    "# prepare dictionary (set) of unique channel labels\n",
    "chans = dict()  # dictionary retains insertion order\n",
    "for img_data in controls_img_data.values():\n",
    "    for chan in img_data:\n",
    "        if chan not in [\"metadata\"]:\n",
    "            chans[chan] = None\n",
    "chans = list(chans.keys())\n",
    "#chans = sorted(chans, key=str.lower)\n",
    "\n",
    "# prepare colormap\n",
    "color_map = laq.get_colormap(len(chans))\n",
    "\n",
    "# prepare bottom and top percentiles for analysis\n",
    "chans_min = {chan: np.nan for chan in chans}\n",
    "chans_max = {chan: np.nan for chan in chans}\n",
    "chans_minmax = {chan: (np.nan, np.nan) for chan in chans}\n",
    "for chan in chans:\n",
    "    print(f\"{chan}:\", flush=True)\n",
    "    minmax = laq.get_chan_data(controls_img_data, chan, \"minmax\")\n",
    "    chans_min[chan] = np.mean(minmax[:, 0])\n",
    "    chans_max[chan] = np.mean(minmax[:, 1])\n",
    "    chans_minmax[chan] = (chans_min[chan], chans_max[chan])\n",
    "    print(\n",
    "        f\"\\tMaximum: {chans_minmax[chan][1]:7.1f} (mean), {np.std(minmax[:, 1]):7.1f} (std)\\n\",\n",
    "        f\"\\tMinimum: {chans_minmax[chan][0]:7.1f} (mean), {np.std(minmax[:, 0]):7.1f} (std)\\n\",\n",
    "    )\n",
    "\n",
    "# get sample statistics\n",
    "samples_img_data = {}\n",
    "start = time.time()\n",
    "for count, sample in enumerate(samples, start=1):\n",
    "    print(f\"SAMPLE: [{count}/{samples_len}] {os.path.basename(sample)}\", end=\"\", flush=True)\n",
    "    samples_img_data[sample] = laq.stats_img_data(laq.get_tiff(sample), chans_min)\n",
    "    print(f\" (-{laq.get_time_left(start, count, samples_len):.1f} s)\", flush=True)\n",
    "print()\n",
    "\n",
    "# sort sample image data and list by time stamp\n",
    "samples_img_data = dict(\n",
    "    sorted(samples_img_data.items(), key=lambda v: v[1][\"metadata\"][\"date_time\"])\n",
    ")\n",
    "samples = [sample for sample in samples_img_data.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b06de0-018d-466a-97bf-0153a8c9ad42",
   "metadata": {},
   "source": [
    "### Data Plots I - Distribution Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511d0d3-9428-407e-a21c-75787b3610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting distribution chart...\\n\", flush=True)\n",
    "\n",
    "# get mean data for plots\n",
    "means = []\n",
    "fig, ax = plt.subplots()\n",
    "for c, chan in enumerate(chans):\n",
    "    means.append(laq.get_chan_data(samples_img_data, chan, \"mean\"))\n",
    "\n",
    "# create violin plot\n",
    "vp = ax.violinplot(means, showmeans=True, showextrema=False)\n",
    "for p in vp[\"bodies\"]:\n",
    "    p.set_facecolor(\"black\")\n",
    "    p.set_edgecolor(\"black\")\n",
    "for l in [\"cmeans\"]:\n",
    "    vp[l].set_edgecolor(\"dimgray\")\n",
    "\n",
    "# adjust axes\n",
    "ax.set_xticks([c for c in range(1, len(chans) + 1)], labels=chans, rotation=90)\n",
    "plt.ylim(bottom=0.0)\n",
    "\n",
    "# add legend\n",
    "legend = plt.legend(\n",
    "    [vp[\"bodies\"][0]],\n",
    "    [\"means\"],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46667f2-73b4-481e-a36b-baea3bf471c5",
   "metadata": {},
   "source": [
    "### Data Plots II - Levey-Jennings Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b124c91-27fc-4182-9472-7d5d0e633a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting Levey-Jennings charts...\\n\", flush=True)\n",
    "\n",
    "# positions in plot\n",
    "for position, sample in enumerate(samples, 1):\n",
    "    print(f\"{position} = {os.path.basename(sample)}\")\n",
    "\n",
    "# prepare variables\n",
    "slice_ext = samples_len - 1  # extend slice to either sides\n",
    "fit_trend = False  # fit a linear regression model of the mean\n",
    "slice_size = min(samples_len, 2 * slice_ext + 1)\n",
    "assert (\n",
    "    slice_size > 3\n",
    "), \"Zero degrees of freedom to estimate the standard deviation from the trend line.\"\n",
    "chan_means = {}\n",
    "chan_extras = {}\n",
    "x_vals = range(1, samples_len + 1)\n",
    "np_nan = np.full(samples_len, np.nan)\n",
    "\n",
    "# create error bar plots\n",
    "for c, chan in enumerate(chans):\n",
    "    # prepare variables\n",
    "    run = {stat: np_nan.copy() for stat in [\"slice\", \"means\", \"stdevs\"]}\n",
    "    trend = {stat: np_nan.copy() for stat in [\"slice\", \"vals\", \"stdevs\"]}\n",
    "\n",
    "    # get image statistics\n",
    "    means = laq.get_chan_data(samples_img_data, chan, \"mean\")\n",
    "    stdevs = laq.get_chan_data(samples_img_data, chan, \"stdev\")\n",
    "    stderrs = laq.get_chan_data(samples_img_data, chan, \"stderr\")\n",
    "    chan_means[chan] = means\n",
    "\n",
    "    # get trend statistics\n",
    "    if fit_trend:\n",
    "        slope, inter = np.polyfit(x_vals, means, deg=1)\n",
    "        trend[\"vals\"] = slope * x_vals + inter\n",
    "    else:\n",
    "        trend[\"vals\"].fill(np.nanmean(means))\n",
    "\n",
    "    # get running statistics\n",
    "    for i, mean in enumerate(means):\n",
    "        run[\"slice\"] = laq.get_run_slice(means, i, slice_ext)\n",
    "        if run[\"slice\"].size == slice_size:\n",
    "            run[\"means\"][i] = np.nanmean(run[\"slice\"])\n",
    "            run[\"stdevs\"][i] = np.nanmean(laq.get_run_slice(stdevs, i, slice_ext))\n",
    "            trend[\"slice\"] = laq.get_run_slice(trend[\"vals\"], i, slice_ext)\n",
    "            trend[\"stdevs\"][i] = np.nanstd(run[\"slice\"], ddof=3)  # estimated: slope, intercept, and mean\n",
    "\n",
    "    # get extrema from trend line\n",
    "    chan_extras_keys = [(\"p2stdev\", \"m2stdev\"), (\"p1stdev\", \"m1stdev\")]\n",
    "    chan_extras[chan] = {\n",
    "        chan_extras_keys[0][0]: trend[\"vals\"] + 2.0 * trend[\"stdevs\"],\n",
    "        chan_extras_keys[1][0]: trend[\"vals\"] + 1.0 * trend[\"stdevs\"],\n",
    "        chan_extras_keys[1][1]: trend[\"vals\"] - 1.0 * trend[\"stdevs\"],\n",
    "        chan_extras_keys[0][1]: trend[\"vals\"] - 2.0 * trend[\"stdevs\"],\n",
    "    }\n",
    "\n",
    "    # plot statistics\n",
    "    for dist in [2.0, 1.0, -1.0, -2.0]:\n",
    "        linestyle = (0, (1, 2))\n",
    "        if abs(dist) == 2.0:\n",
    "            linestyle = linestyle = (0, (1, 4))\n",
    "        plt.plot(\n",
    "            x_vals,\n",
    "            run[\"means\"] + dist * run[\"stdevs\"],\n",
    "            color=\"black\",\n",
    "            linewidth=1,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "    for upper, lower in chan_extras_keys:\n",
    "        plt.fill_between(\n",
    "            x_vals,\n",
    "            chan_extras[chan][upper],\n",
    "            chan_extras[chan][lower],\n",
    "            color=\"black\",\n",
    "            alpha=0.2,\n",
    "        )\n",
    "    plt.plot(x_vals, trend[\"vals\"], color=\"black\", linewidth=1, linestyle=\"solid\")\n",
    "    plt.plot(x_vals, run[\"means\"], color=\"black\", linewidth=1, linestyle=\"dashed\")\n",
    "\n",
    "    # plot y values with errors\n",
    "    plt.errorbar(\n",
    "        x_vals,\n",
    "        means,\n",
    "        yerr=stderrs,\n",
    "        fmt=\"o-\",\n",
    "        linewidth=1,\n",
    "        markersize=2,\n",
    "        color=color_map[c],\n",
    "        label=chan,\n",
    "    )\n",
    "\n",
    "    # adjust axes\n",
    "    plt.ylim(0.0)\n",
    "\n",
    "    # add legend\n",
    "    legend = plt.legend()\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821ac28-4044-472f-870d-a778abbcddc3",
   "metadata": {},
   "source": [
    "### Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e28afa-722d-4bca-aa17-71899104f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# get sample scores\n",
    "scores_img_data = {}\n",
    "start = time.time()\n",
    "for count, sample in enumerate(samples, start=1):\n",
    "    print(f\"SCORE: [{count}/{samples_len}] {os.path.basename(sample)}\", end=\"\", flush=True)\n",
    "    scores_img_data[sample] = laq.score_img_data(laq.get_tiff(sample), chans_minmax)\n",
    "    print(f\" (-{laq.get_time_left(start, count, samples_len):.1f} s)\", flush=True)\n",
    "print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fd25b-1c3b-4a2f-8d7d-883ba350a562",
   "metadata": {},
   "source": [
    "### Data Plots II - Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b0868-0c41-4ffc-8463-dd84cf0d1f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all images with extreme values per channel\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"\\n{chan}:\", flush=True)\n",
    "    outliers = []\n",
    "    for m, mean in enumerate(chan_means[chan]):\n",
    "        if mean > chan_extras[chan][\"p2stdev\"][m]:\n",
    "            outliers.append((\"▲▲ \", m, samples[m], chan, mean))\n",
    "        elif mean > chan_extras[chan][\"p1stdev\"][m]:\n",
    "            outliers.append((\"▲  \", m, samples[m], chan, mean))\n",
    "        elif mean < chan_extras[chan][\"m2stdev\"][m]:\n",
    "            outliers.append((\"▼▼ \", m, samples[m], chan, mean))\n",
    "        elif mean < chan_extras[chan][\"m1stdev\"][m]:\n",
    "            outliers.append((\"▼  \", m, samples[m], chan, mean))\n",
    "    # show color bar at top\n",
    "    cmap = mpl.cm.nipy_spectral\n",
    "    norm = mpl.colors.Normalize(\n",
    "        vmin=np.median(chans_min[chan]), vmax=np.median(chans_max[chan])\n",
    "    )\n",
    "    scalarmappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    scalarmappable.set_array([])\n",
    "    fig = plt.figure(figsize=(min_width, 1))\n",
    "    ax = fig.add_axes([0.0, 0.0, 1, 0.5])\n",
    "    cbar = fig.colorbar(scalarmappable, cax=ax, orientation=\"horizontal\")\n",
    "    plt.show()\n",
    "    if outliers:\n",
    "        # print list of outliers with optional channel images\n",
    "        for indicator, position, sample, channel, mean in outliers:\n",
    "            print(\n",
    "                f\"\\n\\t{indicator} {position} = {os.path.basename(sample)}\"\n",
    "                # f\"  ({mean}) [{chans_minmax[chan][0]}-{chans_minmax[chan][1]}]\"\n",
    "            )\n",
    "            if show_img:\n",
    "                plt.imshow(\n",
    "                    laq.get_chan_img(sample, channel),\n",
    "                    cmap=\"nipy_spectral\",\n",
    "                    vmin=chans_min[chan],\n",
    "                    vmax=chans_max[chan],\n",
    "                    resample=False,\n",
    "                )\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(f\"\\t►  (none)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f945d-0681-45e8-9d85-252ba0ab54a4",
   "metadata": {},
   "source": [
    "### Data Plots III - C-Score Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd815a-6b55-4901-95c0-6325af14b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting C-Score charts...\\n\", flush=True)\n",
    "\n",
    "# positions in plot\n",
    "for position, sample in enumerate(samples, 1):\n",
    "    print(f\"{position} = {os.path.basename(sample)}\")\n",
    "\n",
    "# create stacked bar plots\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"\\n{chan}:\", flush=True)\n",
    "    score_1s = laq.get_chan_data(scores_img_data, chan, \"score_1\")\n",
    "    score_2s = laq.get_chan_data(scores_img_data, chan, \"score_2\")\n",
    "    score_3s = laq.get_chan_data(scores_img_data, chan, \"score_3\")\n",
    "    # prepare stacked bar plot\n",
    "    fig, ax = plt.subplots()\n",
    "    bottom = np.zeros(samples_len)\n",
    "    score_labels = range(1, samples_len + 1)\n",
    "    score_values = {\"Score I\": score_1s, \"Score II\": score_2s, \"Score III\": score_3s}\n",
    "    for score, values in score_values.items():\n",
    "        p = ax.bar(score_labels, values, width=0.5, label=score, bottom=bottom)\n",
    "        bottom += values\n",
    "\n",
    "    # adjust axes\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(1e-1, 1.025e2)\n",
    "    plt.axhline(y=1, color=\"tab:blue\", linestyle=\"dashed\")\n",
    "    plt.axhline(y=10, color=\"tab:orange\", linestyle=\"dashed\")\n",
    "    plt.axhline(y=100, color=\"tab:green\", linestyle=\"dashed\")\n",
    "\n",
    "    # add legend, inverse order\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(\n",
    "        handles[::-1],\n",
    "        labels[::-1],\n",
    "        title=\"C-Score (total)\",\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
