{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dcff70-8d02-491a-a945-53ee1ce19cb6",
   "metadata": {},
   "source": [
    "# LaQuacco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7b728-a8ea-41e4-9a10-a9ccbab594b1",
   "metadata": {},
   "source": [
    "## Laboratory Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efd4c2-cf69-4647-b7b4-f49fc268ee8c",
   "metadata": {},
   "source": [
    "### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0010f-3de0-4fd0-ae62-ae96fa0b3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import definitions as defs  # make functions visible in `__main__`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116fe99-f03c-4105-b901-c53ec1bbeb4c",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e961dd-73e6-4d28-8b16-fc10d8b2b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of concurrent workers\n",
    "processes = multiprocessing.cpu_count() // 2 or 1\n",
    "\n",
    "# define relative samples size for normalization\n",
    "sample_perc = 10\n",
    "\n",
    "# define file search patterns\n",
    "data_dir = r\"Z:\\Archive\\All\\Polaris\\Data\\PhenoImagerHT\\Leidos 2023\" # use a raw string (r\"\")\n",
    "data_ext = \"*unmixed.qptiff\"  # include files matching pattern\n",
    "anti_ext = \"\"  # exclude files matching pattern\n",
    "recurse = True  # find files in subdirectory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14a1c1-5db0-4b20-aab4-ba5ac7b89dcf",
   "metadata": {},
   "source": [
    "### Check Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfad8c-2286-4b4d-89e1-4afc3f6c9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all image files\n",
    "files = sorted(\n",
    "    defs.get_files(\n",
    "        path=data_dir,\n",
    "        pat=data_ext,\n",
    "        anti=anti_ext,\n",
    "        recurse=recurse,\n",
    "    ),\n",
    "    key=str.lower,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(files)} image files in {data_dir}:\")\n",
    "for file in files:\n",
    "    print(f\"{file.replace(data_dir, \".\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6230e-2a76-4829-948a-cabf01f2966c",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f92a28-0ca2-4f6b-814b-b16bd83754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # safe import of main module avoids spawning multiple processes simultaneously\n",
    "    if platform.system() == \"Windows\":\n",
    "        multiprocessing.freeze_support()  # required by 'multiprocessing'\n",
    "\n",
    "    # sample experimental image data\n",
    "    try:\n",
    "        samples = sorted(defs.get_samples(population=files, perc=20), key=str.lower)\n",
    "        sample_args = [(sample, None) for sample in samples]\n",
    "    except ValueError:\n",
    "        print(\"Could not draw samples from experimental population.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # analyze the sample data\n",
    "    with multiprocessing.Pool(processes) as pool:\n",
    "        sample_results = pool.starmap(defs.read_img_data, sample_args)\n",
    "        pool.close()  # wait for worker tasks to complete\n",
    "        pool.join()  # wait for worker process to exit\n",
    "    samples_img_data = {sample: img_data for (sample, img_data) in sample_results}\n",
    "\n",
    "    chans_set = set()  # avoid duplicate entries\n",
    "    for img_data in samples_img_data.values():\n",
    "        for chan in img_data:\n",
    "            if chan not in [\"metadata\"]:\n",
    "                chans_set.add(chan)\n",
    "    chans = sorted(chans_set, key=str.lower)\n",
    "\n",
    "    # prepare colormap\n",
    "    color_map = defs.get_colormap(len(chans))\n",
    "\n",
    "    # prepare lambdas for power transform\n",
    "    chan_lmbdas = {}\n",
    "    for chan in chans:\n",
    "        chan_data = defs.get_chan_data(samples_img_data, chan, \"chan_lmbda\")\n",
    "        chan_mean = defs.get_mean(chan_data)\n",
    "        chan_lmbdas[chan] = chan_mean\n",
    "\n",
    "    # analyze experimental image data\n",
    "    image_args = [(image, chan_lmbdas) for image in files]\n",
    "    with multiprocessing.Pool(processes) as pool:\n",
    "        image_results = pool.starmap(defs.read_img_data, image_args)\n",
    "        pool.close()  # wait for worker tasks to complete\n",
    "        pool.join()  # wait for worker process to exit\n",
    "    images_img_data = {image: img_data for (image, img_data) in image_results}\n",
    "\n",
    "    # sort experimental image data by time stamp\n",
    "    images_img_data = dict(\n",
    "        sorted(images_img_data.items(), key=lambda v: v[1][\"metadata\"][\"date_time\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b06de0-018d-466a-97bf-0153a8c9ad42",
   "metadata": {},
   "source": [
    "### Data Plots I - Distribution Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511d0d3-9428-407e-a21c-75787b3610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure dimensions\n",
    "dpi = plt.rcParams['figure.dpi']\n",
    "min_pixw, min_pixh = 1600, 1200\n",
    "min_width, min_height = min_pixw / dpi, min_pixh / dpi\n",
    "plt.rcParams['figure.figsize'] = [min_width, min_height]\n",
    "\n",
    "# prepare data lists\n",
    "data_means = []\n",
    "data_norms = []\n",
    "\n",
    "# get data for plots\n",
    "fig, ax = plt.subplots()\n",
    "for c, chan in enumerate(chans):\n",
    "    # get statistics summary\n",
    "    signal_means = defs.get_chan_data(images_img_data, chan, \"sign_mean\")\n",
    "    data_means.append(signal_means)\n",
    "    data_norms.append(\n",
    "        defs.boxcox_transform(np.array(signal_means), lmbda=chan_lmbdas[chan])[0]\n",
    "    )\n",
    "\n",
    "# create violin plot\n",
    "vp = ax.violinplot(\n",
    "    data_means, showmeans=False, showmedians=False, showextrema=False\n",
    ")\n",
    "for v in vp[\"bodies\"]:\n",
    "    v.set_facecolor(\"black\")\n",
    "    v.set_edgecolor(\"black\")\n",
    "\n",
    "# create boxplot\n",
    "bp = ax.boxplot(data_norms, meanline=True, showmeans=True)\n",
    "for b in bp[\"medians\"]:\n",
    "    b.set_color(\"black\")\n",
    "for b in bp[\"means\"]:\n",
    "    b.set_color(\"black\")\n",
    "    b.set_linestyle(\"dashed\")\n",
    "ax.set_xticks(\n",
    "    [x for x in range(1, len(chans) + 1)],\n",
    "    labels=chans,\n",
    "    rotation=90,\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "# add legend\n",
    "legend = plt.legend([\"basdf\", \"basdfb\"],\n",
    "    loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=\"small\"\n",
    ")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c30e4e-b29c-4d8b-a383-b0aee6ab55ed",
   "metadata": {},
   "source": [
    "### Data Plots I - Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d76581-cbad-482f-85b7-dd45924975f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whisker information\n",
    "whiskers = bp[\"whiskers\"]\n",
    "extrema_bp = {}\n",
    "for b, chan in zip(range(0, len(whiskers), 2), chans):\n",
    "    (x1, x2), (y1, y2) = whiskers[b].get_data()\n",
    "    (x3, x4), (y3, y4) = whiskers[b + 1].get_data()\n",
    "    extrema_bp[chan] = {\"min\": y2, \"max\": y4}\n",
    "\n",
    "# list all images with extreme values per channel\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"{chan}: [{extrema[chan][\"min\"]}, {extrema[chan][\"max\"]}]\", flush=True)\n",
    "    outliers = []\n",
    "    for n, data_norm in enumerate(data_norms[c]):\n",
    "        if data_norm < extrema_bp[chan][\"min\"] or data_norm > extrema_bp[chan][\"max\"]:\n",
    "            outliers.append((os.path.basename(files[n]), data_norm))\n",
    "    if outliers:\n",
    "        for outlier, extreme in outliers:\n",
    "            print(f\"\\t{outlier}: ({extreme})\")\n",
    "    else:\n",
    "        print(f\"\\t(none)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46667f2-73b4-481e-a36b-baea3bf471c5",
   "metadata": {},
   "source": [
    "### Data Plots II - Levey-Jennings Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b124c91-27fc-4182-9472-7d5d0e633a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure dimensions\n",
    "dpi = plt.rcParams['figure.dpi']\n",
    "min_pixw, min_pixh = 1600, 1200\n",
    "min_width, min_height = min_pixw / dpi, min_pixh / dpi\n",
    "plt.rcParams['figure.figsize'] = [min_width, min_height]\n",
    "\n",
    "# Levey-Jennings chart\n",
    "slice_margin = len(files) - 1  # extend slice to either sides\n",
    "slice_min = False  # don't show data for incomplete slices\n",
    "fit_trend = False  # fit a linear regression model of the mean\n",
    "slice_size = 2 * slice_margin + 1\n",
    "assert (\n",
    "    slice_size > 3\n",
    "), \"Zero degrees of freedom to estimate the standard deviation from the trend line.\"\n",
    "file_len = len(files)\n",
    "xs = range(0, file_len)\n",
    "np_nan = np.full(file_len, np.nan)\n",
    "extrema_lj = {}\n",
    "for c, chan in enumerate(chans):\n",
    "    # prepare variables\n",
    "    trend_stats = {stat: np_nan.copy() for stat in [\"vals\", \"stdevs\", \"where\"]}\n",
    "    run_stats = {stat: np_nan.copy() for stat in [\"slice\", \"means\", \"stdevs\"]}\n",
    "    # get image statistics\n",
    "    signal_means = defs.get_chan_data(images_img_data, chan, \"sign_mean\")\n",
    "    signal_stdevs = defs.get_chan_data(images_img_data, chan, \"sign_stdev\")\n",
    "    signal_stderrs = defs.get_chan_data(images_img_data, chan, \"sign_stderr\")\n",
    "    # get trend statistics\n",
    "    if fit_trend:\n",
    "        slope, inter = np.polyfit(xs, signal_means, deg=1)\n",
    "        trend_stats[\"vals\"] = slope * xs + inter\n",
    "    else:\n",
    "        trend_stats[\"vals\"].fill(defs.get_mean(signal_means))\n",
    "    # get running statistics\n",
    "    for i, mean in enumerate(signal_means):\n",
    "        run_stats[\"slice\"] = defs.get_run_slice(signal_means, i, slice_margin, slice_min)\n",
    "        if not slice_min or run_stats[\"slice\"].size == slice_size:\n",
    "            run_stats[\"means\"][i] = defs.get_mean(run_stats[\"slice\"])\n",
    "            run_stats[\"stdevs\"][i] = defs.get_mean(\n",
    "                defs.get_run_slice(signal_stdevs, i, slice_margin, slice_min)\n",
    "            )\n",
    "            trend_stats[\"stdevs\"][i] = defs.get_stdev(\n",
    "                run_stats[\"slice\"],\n",
    "                defs.get_mean(\n",
    "                    defs.get_run_slice(trend_stats[\"vals\"], i, slice_margin, slice_min)\n",
    "                ),\n",
    "                ddof=3,  # estimated: slope, intercept, and mean\n",
    "            )\n",
    "    if not slice_min:\n",
    "        # fill `stdevs` array with limit values\n",
    "        trend_stats[\"where\"] = np.where(~np.isnan(trend_stats[\"stdevs\"]))[0]\n",
    "        if trend_stats[\"where\"].size > 0:  # channel might be sparse with images\n",
    "            trend_stats[\"stdevs\"][: trend_stats[\"where\"][0]] = trend_stats[\n",
    "                \"stdevs\"\n",
    "            ][\n",
    "                trend_stats[\"where\"][0]\n",
    "            ]  # extend left\n",
    "            trend_stats[\"stdevs\"][trend_stats[\"where\"][-1] :] = trend_stats[\n",
    "                \"stdevs\"\n",
    "            ][\n",
    "                trend_stats[\"where\"][-1]\n",
    "            ]  # extend right\n",
    "    # plot statistics\n",
    "    if chan == chans[-1]:\n",
    "        signal_labels = [os.path.basename(image) for image in images_img_data.keys()]\n",
    "        plt.xticks(rotation=90, fontsize=\"small\")\n",
    "    else:\n",
    "        signal_labels = range(0, len(images_img_data))\n",
    "    for dist in [2.0, 1.0, -1.0, -2.0]:\n",
    "        linestyle = (0, (1, 2))\n",
    "        if abs(dist) == 2.0:\n",
    "            linestyle = linestyle = (0, (1, 4))\n",
    "        plt.plot(\n",
    "            run_stats[\"means\"] + dist * run_stats[\"stdevs\"],\n",
    "            color=\"black\",\n",
    "            linewidth=1,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "    for dist in [2.0, 1.0]:\n",
    "        alpha = 0.2\n",
    "        if abs(dist) == 1.0:\n",
    "            alpha = 0.1\n",
    "        plt.fill_between(\n",
    "            xs,\n",
    "            trend_stats[\"vals\"] + dist * trend_stats[\"stdevs\"],\n",
    "            trend_stats[\"vals\"] - dist * trend_stats[\"stdevs\"],\n",
    "            color=\"black\",\n",
    "            alpha=alpha,\n",
    "        )\n",
    "    plt.plot(trend_stats[\"vals\"], color=\"black\", linewidth=1, linestyle=\"solid\")\n",
    "    plt.plot(run_stats[\"means\"], color=\"black\", linewidth=1, linestyle=\"dashed\")\n",
    "    plt.errorbar(\n",
    "        signal_labels,\n",
    "        signal_means,\n",
    "        yerr=signal_stderrs,\n",
    "        fmt=\"o-\",\n",
    "        linewidth=1,\n",
    "        markersize=2,\n",
    "        color=color_map[c],\n",
    "        label=chan + \" [SIG]\",\n",
    "    )\n",
    "    legend = plt.legend(\n",
    "        loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=\"small\"\n",
    "    )\n",
    "    plt.ylim(bottom=0.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fd25b-1c3b-4a2f-8d7d-883ba350a562",
   "metadata": {},
   "source": [
    "### Data Plots II - Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b0868-0c41-4ffc-8463-dd84cf0d1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whisker information\n",
    "whiskers = bp[\"whiskers\"]\n",
    "extrema = {}\n",
    "for b, chan in zip(range(0, len(whiskers), 2), chans):\n",
    "    (x1, x2), (y1, y2) = whiskers[b].get_data()\n",
    "    (x3, x4), (y3, y4) = whiskers[b + 1].get_data()\n",
    "    extrema[chan] = {\"min\": y2, \"max\": y4}\n",
    "\n",
    "# list all images with extreme values per channel\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"CHANNEL: {chan} [{extrema[chan][\"min\"]}, {extrema[chan][\"max\"]}]\", flush=True)\n",
    "    outliers = []\n",
    "    for n, data_norm in enumerate(data_norms[c]):\n",
    "        if data_norm < extrema[chan][\"min\"] or data_norm > extrema[chan][\"max\"]:\n",
    "            outliers.append((os.path.basename(files[n]), data_norm))\n",
    "    if outliers:\n",
    "        for outlier, extreme in outliers:\n",
    "            print(f\"\\tFILE: {outlier} ({extreme})\")\n",
    "    else:\n",
    "        print(f\"\\tFILE: NONE\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
