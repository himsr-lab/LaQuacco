{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dcff70-8d02-491a-a945-53ee1ce19cb6",
   "metadata": {},
   "source": [
    "# LaQuacco ðŸ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7b728-a8ea-41e4-9a10-a9ccbab594b1",
   "metadata": {},
   "source": [
    "## Laboratory Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efd4c2-cf69-4647-b7b4-f49fc268ee8c",
   "metadata": {},
   "source": [
    "### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0010f-3de0-4fd0-ae62-ae96fa0b3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import laquacco as laq  # required by Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116fe99-f03c-4105-b901-c53ec1bbeb4c",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e961dd-73e6-4d28-8b16-fc10d8b2b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of concurrent workers\n",
    "processes = multiprocessing.cpu_count() // 2 or 1\n",
    "\n",
    "# define relative samples size for normalization\n",
    "sample_perc = 20\n",
    "\n",
    "# define signal threshold for channel statistics\n",
    "chan_thrld = np.nan\n",
    "\n",
    "# define file search patterns\n",
    "data_dir = r\".\\tests\\Polaris\"  # use a raw string (r\"\")\n",
    "data_ext = \"*.tif\"  # include files matching pattern\n",
    "anti_ext = \"\"  # exclude files matching pattern\n",
    "recurse = True  # find files in subdirectories\n",
    "\n",
    "# render channel images of outliers\n",
    "show_img = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14a1c1-5db0-4b20-aab4-ba5ac7b89dcf",
   "metadata": {},
   "source": [
    "### Check Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfad8c-2286-4b4d-89e1-4afc3f6c9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all image files\n",
    "files = sorted(\n",
    "    laq.get_files(\n",
    "        path=data_dir,\n",
    "        pat=data_ext,\n",
    "        anti=anti_ext,\n",
    "        recurse=recurse,\n",
    "    ),\n",
    "    key=str.lower,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(files)} image files in {os.path.abspath(data_dir)}:\")\n",
    "for file in files:\n",
    "    print(f\"{file.replace(data_dir, '.')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6230e-2a76-4829-948a-cabf01f2966c",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f92a28-0ca2-4f6b-814b-b16bd83754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # safe import of main module avoids spawning multiple processes simultaneously\n",
    "    if platform.system() == \"Windows\":\n",
    "        multiprocessing.freeze_support()  # required by 'multiprocessing'\n",
    "\n",
    "    # sample experimental image data\n",
    "    try:\n",
    "        samples = sorted(\n",
    "            laq.get_samples(population=files, perc=sample_perc), key=str.lower\n",
    "        )\n",
    "        sample_args = [(sample, None) for sample in samples]\n",
    "    except ValueError:\n",
    "        print(\"Could not draw samples from experimental population.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    \"\"\"\n",
    "    # analyze the sample data\n",
    "    with multiprocessing.Pool(processes) as pool:\n",
    "        sample_results = pool.starmap(laq.read_img_data, sample_args)\n",
    "        pool.close()  # wait for worker tasks to complete\n",
    "        pool.join()  # wait for worker process to exit\n",
    "    samples_img_data = {sample: img_data for (sample, img_data) in sample_results}\n",
    "    print(samples_img_data)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    sample_results = []\n",
    "    for sample in samples:\n",
    "        sample_results.append(laq.read_img_data(sample))\n",
    "    samples_img_data = {sample: img_data for (sample, img_data) in sample_results}\n",
    "    print()\n",
    "\n",
    "    # prepare channels\n",
    "    chans_set = set()  # avoid duplicate entries\n",
    "    for img_data in samples_img_data.values():\n",
    "        for chan in img_data:\n",
    "            if chan not in [\"metadata\"]:\n",
    "                chans_set.add(chan)\n",
    "    #chans = sorted(chans_set, key=str.lower)\n",
    "    chans = list(chans_set)\n",
    "\n",
    "    # prepare colormap\n",
    "    color_map = laq.get_colormap(len(chans))\n",
    "\n",
    "    # prepare lambdas for power transform\n",
    "    chan_lmbdas = {}\n",
    "    chan_thrlds = {}\n",
    "    for chan in chans:\n",
    "        chan_lmbdas[chan] = laq.get_mean(\n",
    "            laq.get_chan_data(samples_img_data, chan, \"chan_lmbda\")\n",
    "        )\n",
    "        chan_thrlds[chan] = (\n",
    "            laq.get_mean(laq.get_chan_data(samples_img_data, chan, \"chan_thrld\"))\n",
    "            if np.isnan(chan_thrld)\n",
    "            else float(chan_thrld)\n",
    "        )\n",
    "        print(f\"{chan}:\", flush=True)\n",
    "        print(f\"\\tLambda: {chan_lmbdas[chan]},\\n\\tThreshold: {chan_thrlds[chan]}\")\n",
    "    print()\n",
    "\n",
    "    \"\"\"\n",
    "    # analyze experimental image data\n",
    "    image_args = [(image, chan_thrlds) for image in files]\n",
    "    with multiprocessing.Pool(processes) as pool:\n",
    "        image_results = pool.starmap(laq.read_img_data, image_args)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    images_img_data = {image: img_data for (image, img_data) in image_results}\n",
    "    \"\"\"\n",
    "    image_results = []\n",
    "    for file in files:\n",
    "        image_results.append(laq.read_img_data(file, chan_thrlds))\n",
    "    images_img_data = {image: img_data for (image, img_data) in image_results}\n",
    "    print(images_img_data)\n",
    "    print()\n",
    "\n",
    "    # sort experimental image data by time stamp\n",
    "    images_img_data = dict(\n",
    "        sorted(images_img_data.items(), key=lambda v: v[1][\"metadata\"][\"date_time\"])\n",
    "    )\n",
    "\n",
    "    # get min and max values for plotting\n",
    "    chans_minmax = {}\n",
    "    for c, chan in enumerate(chans):\n",
    "        chan_minmaxs =  laq.get_chan_data(images_img_data, chan, \"sign_minmax\")\n",
    "        chans_minmax[chan] = (np.nanmean([min for min, _ in chan_minmaxs]),\n",
    "                              np.nanmean([max for _, max in chan_minmaxs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b06de0-018d-466a-97bf-0153a8c9ad42",
   "metadata": {},
   "source": [
    "### Data Plots I - Distribution Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511d0d3-9428-407e-a21c-75787b3610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure dimensions (global)\n",
    "dpi = plt.rcParams[\"figure.dpi\"]\n",
    "min_pixw, min_pixh = 1600, 1200\n",
    "min_width, min_height = min_pixw / dpi, min_pixh / dpi\n",
    "plt.rcParams[\"figure.figsize\"] = [min_width, min_height]\n",
    "\n",
    "# prepare data lists\n",
    "data_means = []\n",
    "data_norms = []\n",
    "\n",
    "# get data for plots\n",
    "fig, ax = plt.subplots()\n",
    "for c, chan in enumerate(chans):\n",
    "    # get statistics summary\n",
    "    signal_means = laq.get_chan_data(images_img_data, chan, \"sign_mean\")\n",
    "    data_means.append(signal_means)\n",
    "    data_norms.append(\n",
    "        laq.boxcox_transform(np.array(signal_means), lmbda=chan_lmbdas[chan])[0]\n",
    "    )\n",
    "\n",
    "# create violin plot\n",
    "vp = ax.violinplot(data_means, showmeans=False, showmedians=True, showextrema=False)\n",
    "for v in vp[\"bodies\"]:\n",
    "    v.set_facecolor(\"black\")\n",
    "    v.set_edgecolor(\"black\")\n",
    "vp['cmedians'].set_edgecolor('dimgray')\n",
    "\n",
    "# create boxplot\n",
    "bp = ax.boxplot(data_norms, meanline=True, showmeans=True)\n",
    "for b in bp[\"medians\"]:\n",
    "    b.set_color(\"black\")\n",
    "for b in bp[\"means\"]:\n",
    "    b.set_color(\"black\")\n",
    "    b.set_linestyle(\"dashed\")\n",
    "ax.set_xticks(\n",
    "    [x for x in range(1, len(chans) + 1)],\n",
    "    labels=chans,\n",
    "    rotation=90,\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "# add legend\n",
    "legend = plt.legend(\n",
    "    [vp[\"bodies\"][0], bp[\"boxes\"][0]],\n",
    "    [\"measured\", \"normalized\"],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    fontsize=\"small\",\n",
    ")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c30e4e-b29c-4d8b-a383-b0aee6ab55ed",
   "metadata": {},
   "source": [
    "### Data Plots I - Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d76581-cbad-482f-85b7-dd45924975f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get boxplot information\n",
    "boxplots_stats = laq.get_boxplots_stats(bp, chans)\n",
    "\n",
    "# list all images with extreme values per channel\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"\\n{chan}:\", flush=True)\n",
    "    outliers_bp = []\n",
    "    for n, data_norm in enumerate(data_norms[c]):\n",
    "        if data_norm > boxplots_stats[chan][\"w3\"]:\n",
    "            outliers_bp.append((\"â–²  \", n, files[n], chan, data_means[c][n]))\n",
    "        elif data_norm < boxplots_stats[chan][\"w1\"]:\n",
    "            outliers_bp.append((\"â–¼  \", n, files[n], chan, data_means[c][n]))\n",
    "    # show color bar at top\n",
    "    cmap = mpl.cm.nipy_spectral\n",
    "    norm = mpl.colors.Normalize(vmin=chans_minmax[chan][0],\n",
    "                                vmax=chans_minmax[chan][1])\n",
    "    scalarmappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    scalarmappable.set_array([])\n",
    "    fig = plt.figure(figsize=(min_width, 1))\n",
    "    ax = fig.add_axes([0.0, 0.0, 1, 0.5])\n",
    "    cbar = fig.colorbar(scalarmappable, cax=ax, orientation='horizontal')\n",
    "    plt.show()\n",
    "    if outliers_bp:\n",
    "        # print list of outliers with optional channel images\n",
    "        for indicator, position, file, channel, mean in outliers_bp:\n",
    "            print(\n",
    "                f\"\\n\\t{indicator} {position} = {os.path.basename(file)}\",\n",
    "                f\"  ({mean}) [{chans_minmax[chan][0]}-{chans_minmax[chan][1]}]\",\n",
    "            )\n",
    "            if show_img:\n",
    "                plt.imshow(\n",
    "                    laq.get_chan_img(file, channel),\n",
    "                    cmap=\"nipy_spectral\",\n",
    "                    vmin=chans_minmax[chan][0],\n",
    "                    vmax=chans_minmax[chan][1],\n",
    "                    resample=False,\n",
    "                )\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(f\"\\tâ–º  (none)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46667f2-73b4-481e-a36b-baea3bf471c5",
   "metadata": {},
   "source": [
    "### Data Plots II - Levey-Jennings Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b124c91-27fc-4182-9472-7d5d0e633a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levey-Jennings chart\n",
    "slice_margin = len(files) - 1  # extend slice to either sides\n",
    "fit_trend = False  # fit a linear regression model of the mean\n",
    "file_len = len(files)\n",
    "slice_size = min(file_len, 2 * slice_margin + 1)\n",
    "assert (\n",
    "    slice_size > 3\n",
    "), \"Zero degrees of freedom to estimate the standard deviation from the trend line.\"\n",
    "xs = range(0, file_len)\n",
    "np_nan = np.full(file_len, np.nan)\n",
    "signals_lj = {}\n",
    "extrema_lj = {}\n",
    "for c, chan in enumerate(chans):\n",
    "    # prepare variables\n",
    "    run_stats = {stat: np_nan.copy() for stat in [\"slice\", \"means\", \"stdevs\"]}\n",
    "    trend_stats = {stat: np_nan.copy() for stat in [\"slice\", \"vals\", \"stdevs\"]}\n",
    "    # get image statistics\n",
    "    signal_means = laq.get_chan_data(images_img_data, chan, \"sign_mean\")\n",
    "    signal_stdevs = laq.get_chan_data(images_img_data, chan, \"sign_stdev\")\n",
    "    signal_stderrs = laq.get_chan_data(images_img_data, chan, \"sign_stderr\")\n",
    "    signals_lj[chan] = signal_means\n",
    "    # get trend statistics\n",
    "    if fit_trend:\n",
    "        slope, inter = np.polyfit(xs, signal_means, deg=1)\n",
    "        trend_stats[\"vals\"] = slope * xs + inter\n",
    "    else:\n",
    "        trend_stats[\"vals\"].fill(laq.get_mean(signal_means))\n",
    "    # get running statistics\n",
    "    for i, mean in enumerate(signal_means):\n",
    "        run_stats[\"slice\"] = laq.get_run_slice(signal_means, i, slice_margin)\n",
    "        if run_stats[\"slice\"].size == slice_size:\n",
    "            run_stats[\"means\"][i] = laq.get_mean(run_stats[\"slice\"])\n",
    "            run_stats[\"stdevs\"][i] = laq.get_mean(\n",
    "                laq.get_run_slice(signal_stdevs, i, slice_margin)\n",
    "            )\n",
    "            trend_stats[\"slice\"] = laq.get_run_slice(\n",
    "                trend_stats[\"vals\"], i, slice_margin\n",
    "            )\n",
    "            trend_stats[\"stdevs\"][i] = laq.get_stdev(\n",
    "                run_stats[\"slice\"],\n",
    "                mean=laq.get_mean(trend_stats[\"slice\"]),\n",
    "                ddof=3,  # estimated: slope, intercept, and mean\n",
    "            )\n",
    "    # get extrema from trend line\n",
    "    extrema_lj_keys = [(\"p2stdev\", \"m2stdev\"), (\"p1stdev\", \"m1stdev\")]\n",
    "    extrema_lj[chan] = {\n",
    "        extrema_lj_keys[0][0]: trend_stats[\"vals\"] + 2.0 * trend_stats[\"stdevs\"],\n",
    "        extrema_lj_keys[1][0]: trend_stats[\"vals\"] + 1.0 * trend_stats[\"stdevs\"],\n",
    "        extrema_lj_keys[1][1]: trend_stats[\"vals\"] - 1.0 * trend_stats[\"stdevs\"],\n",
    "        extrema_lj_keys[0][1]: trend_stats[\"vals\"] - 2.0 * trend_stats[\"stdevs\"],\n",
    "    }\n",
    "    # plot statistics\n",
    "    if chan == chans[-1]:\n",
    "        signal_labels = [os.path.basename(image) for image in images_img_data.keys()]\n",
    "        plt.xticks(rotation=90, fontsize=\"small\")\n",
    "    else:\n",
    "        signal_labels = range(0, len(images_img_data))\n",
    "    for dist in [2.0, 1.0, -1.0, -2.0]:\n",
    "        linestyle = (0, (1, 2))\n",
    "        if abs(dist) == 2.0:\n",
    "            linestyle = linestyle = (0, (1, 4))\n",
    "        plt.plot(\n",
    "            run_stats[\"means\"] + dist * run_stats[\"stdevs\"],\n",
    "            color=\"black\",\n",
    "            linewidth=1,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "    for upper, lower in extrema_lj_keys:\n",
    "        plt.fill_between(\n",
    "            xs,\n",
    "            extrema_lj[chan][upper],\n",
    "            extrema_lj[chan][lower],\n",
    "            color=\"black\",\n",
    "            alpha=0.2,\n",
    "        )\n",
    "    plt.plot(trend_stats[\"vals\"], color=\"black\", linewidth=1, linestyle=\"solid\")\n",
    "    plt.plot(run_stats[\"means\"], color=\"black\", linewidth=1, linestyle=\"dashed\")\n",
    "    plt.errorbar(\n",
    "        signal_labels,\n",
    "        signal_means,\n",
    "        yerr=signal_stderrs,\n",
    "        fmt=\"o-\",\n",
    "        linewidth=1,\n",
    "        markersize=2,\n",
    "        color=color_map[c],\n",
    "        label=chan + \" [SIG]\",\n",
    "    )\n",
    "    legend = plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=\"small\")\n",
    "    plt.ylim(bottom=0.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fd25b-1c3b-4a2f-8d7d-883ba350a562",
   "metadata": {},
   "source": [
    "### Data Plots II - Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b0868-0c41-4ffc-8463-dd84cf0d1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all images with extreme values per channel\n",
    "for c, chan in enumerate(chans):\n",
    "    print(f\"\\n{chan}:\", flush=True)\n",
    "    outliers_lj = []\n",
    "    for s, signal_lj in enumerate(signals_lj[chan]):\n",
    "        if signal_lj > extrema_lj[chan][\"p2stdev\"][s]:\n",
    "            outliers_lj.append((\"â–²â–² \", s, files[s], chan, signal_lj))\n",
    "        elif signal_lj > extrema_lj[chan][\"p1stdev\"][s]:\n",
    "            outliers_lj.append((\"â–²  \", s, files[s], chan, signal_lj))\n",
    "        elif signal_lj < extrema_lj[chan][\"m2stdev\"][s]:\n",
    "            outliers_lj.append((\"â–¼â–¼ \", s, files[s], chan, signal_lj))\n",
    "        elif signal_lj < extrema_lj[chan][\"m1stdev\"][s]:\n",
    "            outliers_lj.append((\"â–¼  \", s, files[s], chan, signal_lj))\n",
    "    # show color bar at top\n",
    "    cmap = mpl.cm.nipy_spectral\n",
    "    norm = mpl.colors.Normalize(vmin=chans_minmax[chan][0],\n",
    "                                vmax=chans_minmax[chan][1])\n",
    "    scalarmappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    scalarmappable.set_array([])\n",
    "    fig = plt.figure(figsize=(min_width, 1))\n",
    "    ax = fig.add_axes([0.0, 0.0, 1, 0.5])\n",
    "    cbar = fig.colorbar(scalarmappable, cax=ax, orientation='horizontal')\n",
    "    plt.show()\n",
    "    if outliers_lj:\n",
    "        # print list of outliers with optional channel images\n",
    "        for indicator, position, file, channel, mean in outliers_lj:\n",
    "            print(\n",
    "                f\"\\n\\t{indicator} {position} = {os.path.basename(file)}\"\n",
    "                f\"  ({mean}) [{chans_minmax[chan][0]}-{chans_minmax[chan][1]}]\"\n",
    "            )\n",
    "            if show_img:\n",
    "                plt.imshow(\n",
    "                    laq.get_chan_img(file, channel),\n",
    "                    cmap=\"nipy_spectral\",\n",
    "                    vmin=chans_minmax[chan][0],\n",
    "                    vmax=chans_minmax[chan][1],\n",
    "                    resample=False,\n",
    "                )\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(f\"\\tâ–º  (none)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f945d-0681-45e8-9d85-252ba0ab54a4",
   "metadata": {},
   "source": [
    "### Data Plots III - H-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd815a-6b55-4901-95c0-6325af14b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "\n",
    "score_img_datas = laq.score_img_data(files[0], chans_minmax)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(len(chans))\n",
    "score_labels = tuple(score_img_datas.keys())\n",
    "score_values = {\"score_1\": [], \"score_2\": [], \"score_3\": []}\n",
    "for channel, scores in score_img_datas.items():\n",
    "    for score in scores:\n",
    "        score_values[score].append(score_img_datas[channel][score])\n",
    "for score, scores in score_values.items():\n",
    "    p = ax.bar(score_labels, scores, width=0.5, label=score, bottom=bottom)\n",
    "    bottom += scores\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(1e-1, 1.025e2)\n",
    "plt.axhline(y=1, color=\"tab:blue\", linestyle=\"dashed\")\n",
    "plt.axhline(y=10, color=\"tab:orange\", linestyle=\"dashed\")\n",
    "plt.axhline(y=100, color=\"tab:green\", linestyle=\"dashed\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1],\n",
    "          title='H-Score (total)',\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0.5),\n",
    "          fontsize=\"small\",)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f46b6-5849-4fe4-80dd-5057a1b38a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
